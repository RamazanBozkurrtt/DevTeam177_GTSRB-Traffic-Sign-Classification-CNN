{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcba4333-e5a7-40c9-9fbf-37bf74741345",
   "metadata": {},
   "source": [
    "# 1. Gerekli Kütüphanelerin Yüklenmesi\r\n",
    "\r\n",
    "Bu bölümde, derin öğrenme modelimizi geliştirmek ve veri setini işlemek için gerekli olan temel kütüphaneleri yüklüyoruz.\r\n",
    "* **torch & torchvision:** PyTorch derin öğrenme çerçevesi ve görüntü işleme araçları.\r\n",
    "* **transforms:** Görüntüleri tensörlere çevirmek ve veri çoğaltma (augmentation) işlemleri için.\r\n",
    "* **pandas:** Test veri setindeki etiketlerin bulunduğu CSV dosyasını okumak için.\r\n",
    "* **PIL & pathlib:** Görüntü dosyalarını açmak ve dosya yollarını yönetmek için."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda9ccd1-c427-4fca-b6dd-e0a36e7440d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e7df6-f72d-4974-9d02-0a3fc192a452",
   "metadata": {},
   "source": [
    "# 2. Özel Test Veri Seti Sınıfı (Custom Dataset)\n",
    "\n",
    "GTSRB veri setinin **Test** kısmı, Eğitim kısmından farklı bir yapıya sahiptir. Eğitim verileri sınıflara göre klasörlenmişken, Test verileri tek bir klasörde karışık haldedir ve etiketleri bir CSV dosyasında tutulur.\n",
    "\n",
    "Bu nedenle, PyTorch'un standart `ImageFolder` yapısını test verisinde kullanamayız. Aşağıdaki `GTSRBTestDataset` sınıfı:\n",
    "1.  CSV dosyasından dosya isimlerini ve sınıf ID'lerini okur.\n",
    "2.  `__getitem__` fonksiyonu ile her bir görüntüyü diskten yükler ve ilgili dönüşümleri (transform) uygular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c21a91e-2f6b-47a3-8716-b4fb9290f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Test Verisi için Özel Dataset Sınıfı ---\n",
    "class GTSRBTestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        try:\n",
    "            self.annotations = pd.read_csv(csv_file, delimiter=';')\n",
    "        except Exception as e:\n",
    "            print(f\"HATA: '{csv_file}' okunurken sorun: {e}\")\n",
    "            raise e\n",
    "            \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        try:\n",
    "            self.image_filenames = self.annotations['Filename']\n",
    "            self.labels = self.annotations['ClassId']\n",
    "        except KeyError:\n",
    "            print(f\"HATA: CSV dosyasında 'Filename' veya 'ClassId' sütunları bulunamadı.\")\n",
    "            print(\"Lütfen CSV dosyanızı kontrol edin.\")\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.image_filenames[index]\n",
    "        img_path = self.img_dir / img_name\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"HATA: '{img_path}' resmi bulunamadı.\")\n",
    "            return None, None # Hata durumunda None döndür (DataLoader'da işlenir)\n",
    "\n",
    "        label = int(self.labels[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2388b-418e-4bf2-a66c-f1b4062a814e",
   "metadata": {},
   "source": [
    "# 3. Veri Hazırlama ve Yükleme Fonksiyonu (`get_data_loaders`)\n",
    "\n",
    "Bu fonksiyon, veri işleme boru hattının (pipeline) tamamını yönetir ve modele beslenecek `DataLoader` nesnelerini üretir.\n",
    "\n",
    "**Fonksiyonun gerçekleştirdiği temel adımlar:**\n",
    "1.  **Dosya Yolları:** Veri setinin bulunduğu dizinleri ve CSV dosyasını dinamik olarak belirler.\n",
    "2.  **Veri Dönüşümleri (Transforms):**\n",
    "    * *Eğitim Seti:* Modelin ezberlemesini (overfitting) önlemek için **Data Augmentation** (Rastgele döndürme, renk değişimi vb.) uygulanır.\n",
    "    * *Validasyon/Test Seti:* Sadece boyutlandırma ve normalizasyon yapılır; veri bozulmaz.\n",
    "3.  **Veri Yükleme:**\n",
    "    * Eğitim verisi `ImageFolder` ile yüklenir.\n",
    "    * Eğitim verisi, `%80 Eğitim` ve `%20 Validasyon` olacak şekilde rastgele ikiye ayrılır (`random_split`).\n",
    "    * Test verisi, yukarıda yazdığımız özel `GTSRBTestDataset` sınıfı ile yüklenir.\n",
    "4.  **Batchleme:** Veriler karıştırılır (shuffle) ve modelin işleyebileceği paketler (batch) haline getirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d38bf35-fbab-4759-a656-9416a60446c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ANA FONKSİYON: VERİ YÜKLEYİCİLERİ AL ---\n",
    "def get_data_loaders(batch_size=64, num_workers=0):\n",
    "    \"\"\"\n",
    "    Train, Validation ve Test veri yükleyicilerini ve sınıf sayısını döndürür.\n",
    "    \"\"\"\n",
    "    # --- 1. Yollar ---\n",
    "    try:\n",
    "        BASE_DIR = Path(__file__).resolve().parent\n",
    "    except NameError:\n",
    "        BASE_DIR = Path('.').resolve() # İnteraktif pencere için yedek\n",
    "\n",
    "    TRAIN_DIR = BASE_DIR / 'GTSRB' / 'Final_Training' / 'Images'\n",
    "    TEST_DIR = BASE_DIR / 'GTSRB_Final_Test' / 'Final_Test' / 'Images'\n",
    "    TEST_CSV_PATH = BASE_DIR / 'GT-final_test.csv'\n",
    "    \n",
    "    # Yolları kontrol et\n",
    "    if not TRAIN_DIR.exists() or not TEST_DIR.exists() or not TEST_CSV_PATH.exists():\n",
    "        print(\"--- HATA: Dosya Yolu Bulunamadı! ---\")\n",
    "        print(f\"Aranan TRAIN_DIR: {TRAIN_DIR} -> Var mı? {TRAIN_DIR.exists()}\")\n",
    "        print(f\"Aranan TEST_DIR: {TEST_DIR} -> Var mı? {TEST_DIR.exists()}\")\n",
    "        print(f\"Aranan TEST_CSV: {TEST_CSV_PATH} -> Var mı? {TEST_CSV_PATH.exists()}\")\n",
    "        return None, None, None, -1 # Hata durumunda None döndür\n",
    "\n",
    "    IMG_SIZE = 64\n",
    "    VAL_SPLIT = 0.2\n",
    "     # --- 2. Dönüşümler (Transforms) ---\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomRotation(10), # Data augmentation\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2), # Data augmentation\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    val_test_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)), # Augmentation YOK\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    " # --- 4. Veri Setlerini Yükleme ve Ayırma ---\n",
    "    try:\n",
    "        # A. Eğitim ve Validasyon\n",
    "        full_train_dataset = torchvision.datasets.ImageFolder(\n",
    "            root=str(TRAIN_DIR),\n",
    "            transform=train_transforms\n",
    "        )\n",
    "        \n",
    "        NUM_CLASSES = len(full_train_dataset.classes)\n",
    "        print(f\"Eğitim verisi yüklendi. Toplam {NUM_CLASSES} sınıf bulundu.\")\n",
    "\n",
    "        train_size = int((1.0 - VAL_SPLIT) * len(full_train_dataset))\n",
    "        val_size = len(full_train_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "        \n",
    "        # Validasyon setinin transformunu augmentation'sız olanla değiştir\n",
    "        val_dataset.dataset.transform = val_test_transforms\n",
    "        print(f\"Train/Validation ayrımı yapıldı: {len(train_dataset)} Train, {len(val_dataset)} Validation\")\n",
    "\n",
    "        # B. Test\n",
    "        test_dataset = GTSRBTestDataset(\n",
    "            csv_file=TEST_CSV_PATH,\n",
    "            img_dir=TEST_DIR,\n",
    "            transform=val_test_transforms\n",
    "        )\n",
    "        print(f\"Test verisi yüklendi. Boyut: {len(test_dataset)}\")\n",
    "\n",
    "        # --- 5. DataLoaders Oluşturma ---\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "        )\n",
    "        \n",
    "        print(\"DataLoaders (train, val, test) başarıyla oluşturuldu.\")\n",
    "        \n",
    "        # Fonksiyon, bu 4 önemli değişkeni 'return' eder (geri döndürür)\n",
    "        return train_loader, val_loader, test_loader, NUM_CLASSES\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nVeri yüklenirken beklenmedik bir hata oluştu: {e}\")\n",
    "        return None, None, None, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e34f4e-2d57-4056-92db-b3c6c9d73aba",
   "metadata": {},
   "source": [
    "# 4. Fonksiyonun Test Edilmesi ve Kontrol\n",
    "\n",
    "Bu blok, yazdığımız veri yükleme fonksiyonunun (`get_data_loaders`) hatasız çalışıp çalışmadığını kontrol eder.\n",
    "* Veri yükleyicilerin başarıyla oluşturulup oluşturulmadığına bakar.\n",
    "* Eğitim, validasyon ve test setlerindeki veri sayılarını (batch sayısı) ekrana basar.\n",
    "* Örnek bir veri paketinin boyutlarını (Tensor shape) kontrol ederek boyut uyuşmazlığı olup olmadığını doğrular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18758d40-6e0d-46fe-8f7c-d8d3b2dd84d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Veri_Duzenleme.ipynb Test Modunda Çalıştırılıyor ---\n",
      "Eğitim verisi yüklendi. Toplam 43 sınıf bulundu.\n",
      "Train/Validation ayrımı yapıldı: 31367 Train, 7842 Validation\n",
      "Test verisi yüklendi. Boyut: 12630\n",
      "DataLoaders (train, val, test) başarıyla oluşturuldu.\n",
      "\n",
      "Test başarılı. Sınıf sayısı: 43\n",
      "Train loader'da 491 batch var.\n",
      "Val loader'da 123 batch var.\n",
      "Test loader'da 198 batch var.\n",
      "İlk train batch boyutu (Resimler): torch.Size([64, 3, 64, 64])\n",
      "İlk train batch boyutu (Etiketler): torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# --- Test Bloğu ---\n",
    "# Bu dosya DOĞRUDAN çalıştırılırsa (import edilmek yerine),\n",
    "# veri yüklemeyi test et.\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Veri_Duzenleme.ipynb Test Modunda Çalıştırılıyor ---\")\n",
    "    \n",
    "    # 64 batch ve 0 worker ile fonksiyonu test et\n",
    "    train_ldr, val_ldr, test_ldr, num_c = get_data_loaders(batch_size=64, num_workers=0)\n",
    "    \n",
    "    if train_ldr:\n",
    "        print(f\"\\nTest başarılı. Sınıf sayısı: {num_c}\")\n",
    "        print(f\"Train loader'da {len(train_ldr)} batch var.\")\n",
    "        print(f\"Val loader'da {len(val_ldr)} batch var.\")\n",
    "        print(f\"Test loader'da {len(test_ldr)} batch var.\")\n",
    "        \n",
    "        # İlk batch'i almayı dene\n",
    "        try:\n",
    "            data, labels = next(iter(train_ldr))\n",
    "            print(f\"İlk train batch boyutu (Resimler): {data.shape}\")\n",
    "            print(f\"İlk train batch boyutu (Etiketler): {labels.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch alınırken hata: {e}\")\n",
    "    else:\n",
    "        print(\"\\nTest başarısız. Veri yükleyiciler oluşturulamadı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4565efa-6c53-44ef-81b8-57c9160cd57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
